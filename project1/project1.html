<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Project 1: Counterfactual Disparity Measures in a Simple Setting</title>
    <meta charset="utf-8" />
    <meta name="author" content="" />
    <meta name="date" content="2023-03-13" />
    <script src="libs/header-attrs-2.14/header-attrs.js"></script>
    <link href="libs/remark-css-0.0.1/default.css" rel="stylesheet" />
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.8.2/css/all.css" integrity="sha384-oS3vJWv+0UjzBfQzYUhtDYW+Pj2yciDJxpsK1OYPAYjqT085Qq/1cq5FLXAZQ7Ay" crossorigin="anonymous">
    <link rel="stylesheet" href="assets/css/aml-theme.css" type="text/css" />
    <link rel="stylesheet" href="assets/css/aml-fonts.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">


class: title-slide, left, bottom

&lt;font size="50"&gt; Project 1: Counterfactual Disparity Measures in a Simple Setting &lt;/font&gt; 

&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;

**Ashley I Naimi, PhD** &lt;br&gt; Associate Professor &lt;br&gt; Director of Graduate Studies &lt;br&gt; Dept of Epidemiology &lt;br&gt; Emory University &lt;br&gt;

&lt;svg viewBox="0 0 512 512" style="height:1em;position:relative;display:inline-block;top:.1em;" xmlns="http://www.w3.org/2000/svg"&gt;  &lt;path d="M464 64H48C21.49 64 0 85.49 0 112v288c0 26.51 21.49 48 48 48h416c26.51 0 48-21.49 48-48V112c0-26.51-21.49-48-48-48zm0 48v40.805c-22.422 18.259-58.168 46.651-134.587 106.49-16.841 13.247-50.201 45.072-73.413 44.701-23.208.375-56.579-31.459-73.413-44.701C106.18 199.465 70.425 171.067 48 152.805V112h416zM48 400V214.398c22.914 18.251 55.409 43.862 104.938 82.646 21.857 17.205 60.134 55.186 103.062 54.955 42.717.231 80.509-37.199 103.053-54.947 49.528-38.783 82.032-64.401 104.947-82.653V400H48z"&gt;&lt;/path&gt;&lt;/svg&gt; &amp;nbsp; ashley.naimi@emory.edu 




---
# Overview

.font150[

- Context: We'll start with a simple dataset

- Exposure `\(x\)`, mediator `\(m\)`, outcome `\(y\)`, exposure-outcome confounder `\(c\)`, and mediator-outcome confounder `\(l\)`

- These Slides: Three Phases - data management and exploration; analysis; interpretation

- A total of seven steps covering:

  - Setup Project Folder
  - Data Management and Exploration
  - Import, Transform, Explore Raw Data
  - Regression Analysis
  - CDM Analysis
  - Interpretation

]

---
# Overview: The Data


```r
a &lt;- read_csv("./project1_data_raw.csv")

head(a)
```

```
## # A tibble: 6 Ã— 5
##       c     x     l     m     y
##   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
## 1 1.19      0     0     1  122.
## 2 0.733     0     0     0  120.
## 3 1.59      0     0     1  122.
## 4 0.406     1     0     0  120.
## 5 0.273     0     0     0  118.
## 6 0.572     0     0     0  119.
```


---
class: middle, center

.font200[

Phase 1: Data Management and Exploration

]

---
# Step 1: Construct a Project Folder

.font150[

- Create a folder called `Disparities_Project1`

- Create Subfolders: `data`, `code`, `figures`, `misc`, `sandbox`, and `report`

- Move the `project1_data_raw.csv` into the `data` subfolder

- Create an RStudio Project in the `Disparities_Project1` folder

]

---
# Step 2: A Data Management and Exploration File

.font150[

- In the `code` subfolder, create two code files:

  - `data_man.R`
  - `main_analysis.R`

- Open the `data_man.R` file and include the &lt;ins&gt;**preamble**&lt;/ins&gt; at the top:


```r
packages &lt;- c("data.table","tidyverse","skimr","here", "lmtest", "sandwich")

for (package in packages) {
  if (!require(package, character.only=T, quietly=T)) {
    install.packages(package, repos='http://lib.stat.cmu.edu/R/CRAN')
  }
}

for (package in packages) {
  library(package, character.only=T)
}
```

]

---
# Step 3: Import, Explore, and Transform Data

.font150[

- Import the `project1_data_raw.csv` into R using the `read_csv()` function 

- You will need to use the `here()` function

  - `a &lt;- read_csv(here("data", "project1_data_raw.csv"))`

- Explore the data:

  - use the `head()` and/or `tail()` functions
  - use the `skim()` function from the `skimr` package
  - use `ggplot()` to generate some figures

- Transform the data:

  - use the `mutate()` function to log-transform the confounding variable `c`.
  - in this case, re-write the original `c` as a log transformed version `log(c)`.
  - verify that the transformation worked

]

---

# Step 4: Export the Data

.font150[

- Create a new data file called `project1_data_analysis.csv` with the transformed `c`

- You should use the `write_csv()` function and the `here()` function to export to the `data` subfolder

]

---
class: middle, center

.font200[

Phase 2: Analysis

]

---

# Step 1: Set Up and Import

.font150[

- Open the `main_analysis.R` file and include the &lt;ins&gt;**preamble**&lt;/ins&gt; at the top. Add the `lmtest` and `sandwich` packages to the list.

- Import the `project1_data_analysis.csv` data, and explore. For example: 


```r
head(a)
tail(a)

GGally::ggpairs(a[,c("c","y")])
```

]

---

# Step 2: Basic Regression

.font150[

- Fit an outcome model regressing `\(y\)` against all other variables in the data

- Fit a propensity score model for the exposure `\(x\)` adjusting for `\(c\)`

  - Create a PS overlap plot for the exposure and save the figure using `ggsave()`
  - Construct IP weights for the exposure and look at the distribution using `summary()`

- Fit a propensity score model for the mediator `\(m\)` adjusting for `\(x\)`, `\(l\)`, and `\(c\)`

  - Create a PS overlap plot for the mediator and save the figure using `ggsave()`
  - Construct IP weights for the exposure and look at the distribution using `summary()`

- Interpret these models, figures, and summaries

]

---

# Step 3: Exposure - Outcome Association

.font150[

a. Fit a linear regression model for the unadjusted association between `\(y\)` and `\(x\)`. Use the `lm` function.

b. Fit a conditionally adjusted regression model for the association between `\(y\)` and `\(x\)` adjusting for `\(c\)` using the `lm` function.

c. Fit a marginally adjusted regression model (g computation) for the association between `\(y\)` and `\(x\)` adjusted for `\(c\)`. Use the bootstrap to obtain standard errors.

d. Fit an inverse probability weighted regression model to estimate the association between `\(y\)` and `\(c\)` adjusted for `\(c\)`. Use the robust (sandwich) variance estimator to obtain standard errors.

]

---

# Step 3a: Exposure - Outcome Association

.font150[

a. Fit a linear regression model for the unadjusted association between `\(y\)` and `\(x\)`. Use the `lm` function. For example:


```r
# crude
res_tabl1a &lt;- summary(lm(y ~ x, data = a))$coefficients[2, 1:2]
```


]


---

# Step 3b: Exposure - Outcome Association

.font150[

b. Fit a conditionally adjusted regression model for the association between `\(y\)` and `\(x\)` adjusting for `\(c\)` using the `lm` function. For example:


```r
# conditionally adjusted
res_tabl1b &lt;- summary(lm(y ~ x + c, data = a))$coefficients[2, 1:2]
```

]

---

# Step 3c: Exposure - Outcome Association

.font150[

c. Fit a marginally adjusted regression model (g computation) for the association between `\(y\)` and `\(x\)` adjusted for `\(c\)`. Use the bootstrap to obtain standard errors. For example:


```r
# marginally standardized
mod &lt;- lm(y ~ x + c, data = a)

mu1 &lt;- predict(mod, newdata=transform(a,x=1), type = "response")
mu0 &lt;- predict(mod, newdata=transform(a,x=0), type = "response")
theta &lt;- mean(mu1) - mean(mu0)

boot_res &lt;- NULL
for(i in 1:500){
  set.seed(i)
  index &lt;- sample(1:nrow(a), nrow(a), replace = T)
  boot_dat &lt;- a[index,]
  
  mod_ &lt;- lm(y ~ x + c, data = boot_dat)
  mu1_ &lt;- predict(mod_, newdata=transform(boot_dat,x=1), type = "response")
  mu0_ &lt;- predict(mod_, newdata=transform(boot_dat,x=0), type = "response")
  boot_res &lt;- rbind(boot_res, 
                    mean(mu1_) - mean(mu0_))
  
}

res_tabl2 &lt;- c(theta, sd(boot_res))
```

]

---

# Step 3d: Exposure - Outcome Association

.font150[

d. Fit an inverse probability weighted regression model to estimate the association between `\(y\)` and `\(c\)` adjusted for `\(c\)`. Use the robust (sandwich) variance estimator to obtain standard errors. For example:


```r
# ps model for the exposure
ps_model &lt;- glm(x ~ c, data = a, family = binomial("logit"))
summary(ps_model)

# construct exposure weights

a &lt;- a %&gt;%  mutate(sw_x = (mean(x)/ps_model$fitted.values)*x + 
                     ((1 - mean(x))/(1 - ps_model$fitted.values))*(1 - x))

summary(a$sw_x)

# ip weighting

mod_ipw &lt;- lm(y ~ x, data = a, weights=sw_x)

res_tabl3 &lt;- coeftest(mod_ipw,
                      vcov = vcovHC(mod_ipw, type = "HC3"))[2,1:2]
```

]

---

# Step 4: Counterfactual Disparity Measures

.font150[

a. Estimate the association that would remain if we set the mediator to `m = 0` using the structural transformation method.

b. Estimate the same CDM in Step 4a using inverse probability weighting.

For both steps, you'll need to determine and evaluate the referent level for the mediator:


```r
# determine what the referent level for the mediator is:
a %&gt;% 
  group_by(m) %&gt;% 
  count()
```


]

---

# Step 4a: Counterfactual Disparity Measures

.font150[

a. Using the structural transformation method.


```r
## using structural transformation
# start with a regression for estimating effect of mediator on outcome:
struct_trans1 &lt;- lm(y ~ x + l + m + c + x*m, data = a)
st_coefs &lt;- summary(struct_trans1)$coefficients[c("m","x:m"), 1]
# create transformed outcome
a &lt;- a %&gt;% mutate(y_tilde = y - m*st_coefs[1] - x*m*st_coefs[2])
# estimate CDM
cdm_est &lt;- summary(lm(y_tilde ~ x + c, data=a))$coefficients[2,1]

# bootstrap
boot_res_cdm &lt;- NULL
for(i in 1:500){
  set.seed(i)
  index &lt;- sample(1:nrow(a), nrow(a), replace = T)
  boot_dat &lt;- a[index,]
  
  mod_ &lt;- lm(y_tilde ~ x + c, data = boot_dat)
  cdm_est_ &lt;- summary(mod_)$coefficients[2,1]
  boot_res_cdm &lt;- rbind(boot_res_cdm, cdm_est_)
}

res_tabl4 &lt;- c(cdm_est,sd(boot_res_cdm))
```


]

---

# Step 4b: Counterfactual Disparity Measures

.font150[

a. Using IP weighting.


```r
## propensity score model exposure
ps_model &lt;- glm(x ~ c, data = a, family = binomial("logit"))
# construct exposure weights
a &lt;- a %&gt;%  mutate(sw_x = (mean(x)/ps_model$fitted.values)*x + 
                     ((1 - mean(x))/(1 - ps_model$fitted.values))*(1 - x))
summary(a$sw_x)

## propensity score model mediator
ps_model_m &lt;- glm(m ~ l + x + c, data = a, family = binomial("logit"))
# construct mediator weights
a &lt;- a %&gt;%  mutate(sw_m = (mean(m)/ps_model_m$fitted.values)*m + 
                     ((1 - mean(m))/(1 - ps_model_m$fitted.values))*(1 - m))
summary(a$sw_m)

ipw_model &lt;- lm(y ~ x + m + x*m, data = a, weights = sw_x*sw_m)
res_tabl5 &lt;- coeftest(ipw_model,
                      vcov = vcovHC(ipw_model, type = "HC3"))[2,1:2]
```
]

---
# Step 5: Combine All Results


```r
## pulling the results together
res_tabl &lt;- data.frame(
  rbind(res_tabl1a,
        res_tabl1b,
        res_tabl2,
        res_tabl3,
        res_tabl4,
        res_tabl5)
)

row.names(res_tabl) &lt;- c("ATE: Crude", 
                         "ATE: Conditionally Adjusted",
                         "ATE: Marginally Standardized",
                         "ATE: IP Weighted",
                         "CDM: Structural Transformation",
                         "CDM: IP Weighted") 
res_tabl &lt;- res_tabl %&gt;% 
  rownames_to_column(var = "Method")

res_tabl &lt;- res_tabl %&gt;% 
  mutate(LCL = Estimate - 1.96*Std..Error,
         UCL = Estimate + 1.96*Std..Error)

## export results to spreadsheet
write_csv(res_tabl, here("misc","project1_results.csv"))
```

---
# Step 5: Combine the Results


|          	                    |Estimate|Std Error  |LCL   |UCL  |
|-------------------------------|--------|-----------|------|-----|
|ATE: Crude	                    | 3.03	 |0.14	     | 2.76	| 3.31|
|ATE: Conditionally Adjusted	  | 2.50	 |0.10	     | 2.31	| 2.69|
|ATE: Marginally Standardized	  | 2.50	 |0.11	     | 2.27	| 2.73|
|ATE: IP Weighted	              | 2.53	 |0.16	     | 2.22	| 2.84|
|CDM: Structural Transformation | 2.13	 |0.12	     | 1.93	| 2.34|
|CDM: IP Weighted	              | 2.16	 |0.17	     | 1.81	| 2.50|

---
class: middle, center

.font200[

Phase 3: Interpretation

]


---
# Step 6: Why are the CDMs different from the ATEs?

- ATEs in the Table above represent a **difference in two means**:
  - Mean of `\(y\)` if `\(x = 1\)`
  - Mean of `\(y\)` if `\(x = 0\)`

- CDMs in the Table above represent a **difference in two means**:
  - Mean of `\(y\)` if `\(x = 1\)` if `\(m\)` was set to zero
  - Mean of `\(y\)` if `\(x = 0\)` if `\(m\)` was set to zero

- The CDM can be *smaller* than the ATE for two reasons:
  - The mean of `\(y\)` if `\(x = 1\)` for the CDM is *lower* than for the ATE
  - The mean of `\(y\)` if `\(x = 0\)` for the CDM is *higher* than for the ATE
  
- Let's explore this in our data

---
# Step 6: Why are the CDMs different from the ATEs?


```r
ate_mu1_ipw &lt;- mean(predict(mod_ipw, newdata=transform(a,x=1), type="response"))
ate_mu0_ipw &lt;- mean(predict(mod_ipw, newdata=transform(a,x=0), type="response"))

cdm_mu1_st &lt;- mean(predict(cdm_model, newdata=transform(a,x=1), type="response"))
cdm_mu0_st &lt;- mean(predict(cdm_model, newdata=transform(a,x=0), type="response"))

cdm_mu1_ipw &lt;- mean(predict(ipw_model, newdata=transform(a,x=1), type="response"))
cdm_mu0_ipw &lt;- mean(predict(ipw_model, newdata=transform(a,x=0), type="response"))

write_csv(
  tibble(
    Model = c("ATE: Marginally Standardized",
              "ATE: IP Weighted",
              "CDM: Structural Transformation",
              "CDM: IP Weighted"),
    mu1 = c(mean(mu1), ate_mu1_ipw, cdm_mu1_st, cdm_mu1_ipw),
    mu0 = c(mean(mu0), ate_mu0_ipw, cdm_mu0_st, cdm_mu0_ipw)
  ), 
  file = here("misc","predicted_outcomes_cdm.csv")
)
```

---
# Step 6: Why are the CDMs different from the ATEs?

|          	                   |mu1       |mu0      |
|------------------------------|----------|---------|
|ATE: Marginally Standardized	 | 122.95	  | 120.45	|
|ATE: IP Weighted	             | 122.97	  | 120.45	|
|CDM: Structural Transformation| 122.37	  | 120.24	|
|CDM: IP Weighted	             | 122.64	  | 120.50	|

- In both cases, `mu1` for the ATE goes down when translating to the CDM. 

- For the structural transformation method, `mu0` goes down (but less than `mu1` goes down, leading to `\(CDM &lt; ATE\)`)

- For the IP weighted method, `mu0` increases, leading to `\(CDM &lt; ATE\)`

---
# Step 7: Interpretation

After adjusting for confounding variables, the mean of `\(y\)` among individuals with `\(x = 1\)` is 2.5 units (95% CI: 2.31, 2.69) higher than the mean of `\(y\)` among individuals with `\(x = 0\)`. 

This mean difference would be reduced to 2.13	units (95% CI: 1.93, 2.34) if the mediator value `\(m\)` was set to zero for all individuals in the population.

These results suggest that `\(M\)` explains roughly `\(\frac{2.5 - 2.13}{2.5} \approx 15\%\)` of the overall association between `\(x\)` and `\(y\)`. 

---
class: middle, center

.font200[

Q&amp;A

]

---
class: title-slide, left, bottom

&lt;font size="50"&gt; Project 1: Counterfactual Disparity Measures in a Simple Setting &lt;/font&gt; 

&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;

**Ashley I Naimi, PhD** &lt;br&gt; Associate Professor &lt;br&gt; Emory University &lt;br&gt;

&lt;svg viewBox="0 0 512 512" style="height:1em;position:relative;display:inline-block;top:.1em;" xmlns="http://www.w3.org/2000/svg"&gt;  &lt;path d="M464 64H48C21.49 64 0 85.49 0 112v288c0 26.51 21.49 48 48 48h416c26.51 0 48-21.49 48-48V112c0-26.51-21.49-48-48-48zm0 48v40.805c-22.422 18.259-58.168 46.651-134.587 106.49-16.841 13.247-50.201 45.072-73.413 44.701-23.208.375-56.579-31.459-73.413-44.701C106.18 199.465 70.425 171.067 48 152.805V112h416zM48 400V214.398c22.914 18.251 55.409 43.862 104.938 82.646 21.857 17.205 60.134 55.186 103.062 54.955 42.717.231 80.509-37.199 103.053-54.947 49.528-38.783 82.032-64.401 104.947-82.653V400H48z"&gt;&lt;/path&gt;&lt;/svg&gt; &amp;nbsp; ashley.naimi@emory.edu &lt;br&gt; &lt;svg viewBox="0 0 496 512" style="height:1em;position:relative;display:inline-block;top:.1em;" xmlns="http://www.w3.org/2000/svg"&gt;  &lt;path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"&gt;&lt;/path&gt;&lt;/svg&gt; &amp;nbsp; ainaimi &lt;br&gt;

    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "solarized-light",
"highlightLanguage": "R",
"highlightLines": true,
"countIncrementalSlides": false,
"ratio": "16:9"
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
